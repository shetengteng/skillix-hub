# MEMORY.md 自动提炼机制设计

## 背景与动机

### 当前问题

MEMORY.md 定位为"核心记忆"，存储长期有效的高价值信息。但当前设计中：

1. **MEMORY.md 从未被写入过实际内容**——自创建以来一直是空模板
2. **唯一的写入方式是用户说"记住这个"**——用户很少会这样说
3. **daily jsonl 的加载有衰减策略**——默认配置下，超过 7 天的事实完全不会被加载

这导致了一个核心矛盾：**重要的项目原则、架构决策、用户偏好等信息，随着时间推移会从 daily 加载窗口中消失，而 MEMORY.md 又没有机制来承接这些信息**。

### 衰减加载策略回顾

当前 daily 事实的加载规则（`jsonl.py` `_apply_decay()`）：

| 时间范围 | 加载策略 | 默认配置 |
|---------|---------|---------|
| 最近 N 天 | 全量加载 | `load_days_full = 2` |
| N ~ M 天前 | 每天最多 K 条 | `load_days_partial = 5`, `partial_per_day = 3` |
| M ~ X 天前 | 只加载高置信度 (≥0.9) | `load_days_max = 7` |
| X 天前 | 完全不加载 | 7 天后消失 |
| 总上限 | 最多 L 条 | `facts_limit = 15` |

**实际效果**：一条重要的项目原则（如"测试文件必须放在 tests/ 目录下"），如果只存在于 daily jsonl 中，7 天后 AI 就完全看不到了。

### 目标

设计一个自动提炼机制，将 daily jsonl 中经过验证的、高价值的事实自动提炼到 MEMORY.md，使其成为**用户和 AI 共同维护的核心记忆**。

---

## 设计方案

### 核心思路

```
daily/*.jsonl（流水事实，短期）
        │
        │  自动提炼
        ▼
   MEMORY.md（核心记忆，永久）
```

不改变 MEMORY.md 的"核心记忆"定位，而是增加一个**从 daily 到 MEMORY.md 的自动提炼通道**，与用户手动编辑并存。

### 提炼时机

| 方案 | 触发时机 | 优势 | 劣势 |
|------|---------|------|------|
| A. sessionEnd Hook | 每次会话关闭时 | 实时性好，无需额外调度 | 每次会话都执行，可能频繁 |
| B. 定期任务 | 每天/每周一次 | 批量处理效率高 | 需要额外调度机制 |
| C. sessionStart Hook | 每次会话开始时 | 加载前先更新，保证最新 | 增加会话启动延迟 |

**推荐方案 A**：在 `sessionEnd` Hook 中执行。理由：
- sessionEnd 是 fire-and-forget，不影响用户体验
- 当前 sessionEnd 已有 `sync_and_cleanup.py`，可以在同步索引后追加提炼步骤
- 不需要额外的调度机制

### 提炼规则

#### 哪些事实应该被提炼到 MEMORY.md

| 条件 | 说明 | 权重 |
|------|------|------|
| `memory_type = "O"` | 用户偏好/观点，天然属于核心记忆 | 高 |
| `confidence >= 0.9` | 高置信度事实 | 中 |
| 重复出现 ≥ 2 次 | 多次被提取说明确实重要 | 高 |
| 包含"原则"、"规范"、"规则"等关键词 | 项目规范类信息 | 高 |
| 存活超过 N 天未被删除 | 经过时间验证 | 中 |
| 已在 MEMORY.md 中存在 | 避免重复 | 排除 |

#### 提炼不应该包含的内容

| 排除条件 | 说明 |
|---------|------|
| `type = "session_start"` / `"session_end"` | 系统事件，不是事实 |
| `deleted_at` 非空 | 已删除的事实 |
| 纯临时性信息 | 如"当前正在修复 bug X"（已完成的任务） |
| 与已有核心记忆重复 | 避免冗余 |

### MEMORY.md 的章节映射

提炼时根据 `memory_type` 将事实写入对应章节：

| memory_type | MEMORY.md 章节 | 示例 |
|-------------|---------------|------|
| `O` (Opinion) | `## 用户偏好` | "用户偏好 TypeScript" |
| `W` (World) + 关键词匹配"原则/规范/规则" | `## 项目规范` | "测试文件必须放在 tests/ 目录下" |
| `W` (World) + 关键词匹配"决策/选择/使用" | `## 重要决策` | "项目使用 PostgreSQL 数据库" |
| `W` (World) + 其他 | `## 项目背景` | "前端使用 React + TypeScript" |
| `B` (Biographical) | `## 项目背景` | "2026-02-17 完成了 API 重构" |

### 去重策略

提炼前需要检查 MEMORY.md 中是否已存在语义相同的内容：

1. **精确匹配**：事实内容与 MEMORY.md 中某行完全相同 → 跳过
2. **模糊匹配**：使用简单的关键词重叠检测（不依赖嵌入模型，避免性能开销）
   - 提取事实中的实体标签（entities）
   - 检查 MEMORY.md 中是否已有包含相同实体组合的行
   - 如果重叠度 > 70% → 跳过

### 写入格式

提炼的内容以 Markdown 列表项追加到对应章节末尾：

```markdown
## 用户偏好

- 用户偏好 TypeScript（confidence: 0.9）
- 中文回答

## 项目规范

- 测试文件必须放在 tests/ 目录下对应的 skill 子目录中，不能放在 skills/ 目录内部
- 测试使用项目自定义的 assert 框架和 run_tests.js 运行器，不使用 jest

## 重要决策

- Playwright Skill 文档策略：优先使用 Skill CLI 命令，MCP tools 作为补充
- click 用 forceJsClick 参数而非自动 fallback，让用户显式控制

## 项目背景

- 前端使用 React + TypeScript
- Playwright Skill 的 48 个 CLI 工具覆盖了 MCP Server 的 22 个 browser_* tools
```

---

## 实现方案

### 新增脚本：`distill_to_memory.py`

位置：`skills/memory/scripts/service/memory/distill_to_memory.py`

```
输入：project_path
流程：
  1. 读取 MEMORY.md 现有内容
  2. 读取 daily/*.jsonl 中所有未删除的 type=fact 事实
  3. 按提炼规则筛选候选事实
  4. 去重：排除已在 MEMORY.md 中存在的
  5. 按 memory_type 分类到对应章节
  6. 追加写入 MEMORY.md
  7. 记录提炼日志
输出：提炼了多少条，写入了哪些章节
```

### 集成到 sessionEnd Hook

在 `sync_and_cleanup.py` 的 `main()` 中，在 `sync_index()` 之后、`clean_old_logs()` 之前调用：

```python
def main():
    ...
    sync_index(project_path)
    distill_to_memory(project_path)  # 新增
    log_session_end(memory_dir, event)
    clean_old_logs()
    ...
```

### 配置项

在 `_DEFAULTS` 中新增：

```python
"distill": {
    "enabled": True,
    "min_confidence": 0.85,
    "min_age_days": 1,
    "max_items_per_run": 5,
    "keywords_rules": {
        "项目规范": ["原则", "规范", "规则", "必须", "不能", "禁止"],
        "重要决策": ["决定", "选择", "使用", "采用", "方案"],
    },
}
```

| 配置项 | 说明 | 默认值 |
|--------|------|--------|
| `distill.enabled` | 是否启用自动提炼 | `true` |
| `distill.min_confidence` | 最低置信度阈值 | `0.85` |
| `distill.min_age_days` | 事实至少存在 N 天才提炼（避免提炼临时信息） | `1` |
| `distill.max_items_per_run` | 每次最多提炼 N 条（避免一次写入过多） | `5` |
| `distill.keywords_rules` | 关键词到章节的映射规则 | 见上 |

### 安全机制

1. **只追加不修改**：提炼脚本只在章节末尾追加新行，不修改或删除已有内容
2. **幂等性**：去重检测确保同一事实不会被重复提炼
3. **限流**：`max_items_per_run` 限制每次提炼数量，避免一次性写入大量内容
4. **最低年龄**：`min_age_days` 确保只提炼经过一定时间验证的事实
5. **日志记录**：每次提炼操作记录到日志，方便审计
6. **可禁用**：通过 `distill.enabled = false` 完全关闭

---

## 数据流全景图（提炼后）

```
┌──────────────────────────────────────────────────────────────┐
│                    记忆数据流（含自动提炼）                      │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│  会话中 ──→ save_fact.py ──→ daily/YYYY-MM-DD.jsonl          │
│                                    │                         │
│  会话结束 ──→ save_summary.py ──→ sessions.jsonl             │
│                                    │                         │
│  sessionEnd Hook:                  │                         │
│    ① sync_index.py ──→ index.sqlite（搜索索引）               │
│    ② distill_to_memory.py ──→ MEMORY.md（核心记忆）  ← 新增   │
│    ③ log_session_end ──→ daily.jsonl（元数据）                │
│    ④ clean_old_logs                                          │
│                                                              │
│  下次会话 sessionStart:                                       │
│    load_memory.py ──→ 加载 MEMORY.md + daily(近期) + 上次摘要  │
│                                                              │
│  ┌─────────────────────────────────────────────┐             │
│  │ MEMORY.md 的写入来源（提炼后）：               │             │
│  │  1. 用户说"记住这个" → AI 手动编辑            │             │
│  │  2. distill_to_memory.py → 自动从 daily 提炼  │  ← 新增    │
│  │  3. 用户直接编辑文件                          │             │
│  └─────────────────────────────────────────────┘             │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

---

## 提炼流程详细设计

### 步骤 1：读取 MEMORY.md 现有内容

```python
def _parse_memory_md(memory_md_path):
    """解析 MEMORY.md，返回 {章节名: [行内容列表]}"""
    sections = {}
    current_section = None
    with open(memory_md_path, "r") as f:
        for line in f:
            line = line.rstrip()
            if line.startswith("## "):
                current_section = line[3:].strip()
                sections[current_section] = []
            elif current_section and line.startswith("- "):
                sections[current_section].append(line[2:].strip())
    return sections
```

### 步骤 2：筛选候选事实

```python
def _select_candidates(daily_dir, existing_items, config):
    """从 daily 中筛选符合提炼条件的事实"""
    all_facts = read_daily_facts(daily_dir)
    candidates = []
    
    for fact in all_facts:
        if fact.get("deleted_at"):
            continue
        if fact.get("type") != "fact":
            continue
        
        confidence = fact.get("confidence", 0)
        if confidence < config["min_confidence"]:
            continue
        
        age = (utcnow() - parse_iso(fact["timestamp"])).days
        if age < config["min_age_days"]:
            continue
        
        content = fact.get("content", "")
        if _is_duplicate(content, existing_items):
            continue
        
        candidates.append(fact)
    
    # O 类型优先，然后按置信度排序
    candidates.sort(key=lambda x: (
        0 if x.get("memory_type") == "O" else 1,
        -x.get("confidence", 0)
    ))
    
    return candidates[:config["max_items_per_run"]]
```

### 步骤 3：分类到章节

```python
def _classify_to_section(fact, keywords_rules):
    """根据 memory_type 和关键词将事实分类到 MEMORY.md 章节"""
    mtype = fact.get("memory_type", "W")
    content = fact.get("content", "")
    
    if mtype == "O":
        return "用户偏好"
    
    if mtype == "B":
        return "项目背景"
    
    # W 类型根据关键词细分
    for section, keywords in keywords_rules.items():
        if any(kw in content for kw in keywords):
            return section
    
    return "项目背景"
```

### 步骤 4：追加写入 MEMORY.md

```python
def _append_to_memory_md(memory_md_path, section_items):
    """将提炼的事实追加到 MEMORY.md 对应章节"""
    content = open(memory_md_path, "r").read()
    
    for section, items in section_items.items():
        section_header = f"## {section}"
        if section_header not in content:
            content += f"\n{section_header}\n\n"
        
        insert_pos = content.index(section_header) + len(section_header)
        next_section = content.find("\n## ", insert_pos)
        if next_section == -1:
            next_section = len(content)
        
        new_lines = "\n".join(f"- {item}" for item in items)
        section_end = content[:next_section].rstrip()
        content = section_end + "\n" + new_lines + "\n" + content[next_section:]
    
    with open(memory_md_path, "w") as f:
        f.write(content)
```

---

## 与现有设计的兼容性

| 现有组件 | 影响 | 说明 |
|---------|------|------|
| `load_memory.py` | 无需修改 | 已经会加载 MEMORY.md 全文 |
| `sync_index.py` | 无需修改 | 已经会同步 MEMORY.md 到 SQLite |
| `update.py` | 无需修改 | 已经不触碰 MEMORY.md |
| `manage edit` | 无需修改 | 用户仍可手动编辑 |
| `manage cleanup` | 无需修改 | 只清理 jsonl，不影响 MEMORY.md |
| SKILL.md | 需更新 | 补充自动提炼的说明 |
| `memory-rules.mdc` | 需更新 | 补充"不要重复 MEMORY.md 中已有内容"的规则 |

---

## 预期效果

### 提炼前（当前状态）

```markdown
# 核心记忆

## 用户偏好

## 项目背景

## 重要决策
```

AI 在第 8 天打开项目时，看不到任何之前的项目原则和决策。

### 提炼后（预期状态）

```markdown
# 核心记忆

## 用户偏好

- 中文回答
- 通过 commit 时生成的 message 需要英文

## 项目规范

- 测试文件必须放在 tests/ 目录下对应的 skill 子目录中，不能放在 skills/ 目录内部
- 测试使用项目自定义的 assert 框架和 run_tests.js 运行器，不使用 jest
- 不要随便写 md 文档，每次编写需要询问

## 重要决策

- Playwright Skill 文档策略：优先使用 Skill CLI 命令，MCP tools 作为补充
- CDP 端口就绪用轮询检测替代固定等待（15s 超时自动 kill）
- click 用 forceJsClick 参数而非自动 fallback，让用户显式控制

## 项目背景

- Playwright Skill 的 48 个 CLI 工具覆盖了 MCP Server 的 22 个 browser_* tools
```

AI 在任何时候打开项目，都能看到完整的核心记忆。
