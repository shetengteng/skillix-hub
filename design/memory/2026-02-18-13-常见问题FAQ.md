# 方案 C：常见问题 FAQ

> **版本**: v1.0
> **创建日期**: 2026-02-18
> **系列**: 方案 C 设计文档 ([返回总览](./2026-02-18-01-总览与设计理念.md))

---

## Q1: 如果没有触发上下文压缩，信息会丢失吗？

**简短回答**：**不会**。即使 preCompact 没有触发，stop Hook 会在任务完成时兜底保存。

### 详细分析

记忆系统有两个保存时机：

| 保存时机 | Hook | 触发条件 | 保存内容 |
|----------|------|----------|----------|
| 上下文压缩前 | preCompact | 上下文使用率 ≥ 80% | 细粒度事实（daily.jsonl） |
| 任务完成后 | stop | Agent 完成任务（status=completed） | 会话摘要 + 关键事实（sessions.jsonl + daily.jsonl） |

### 场景分析

**场景 1：长会话（上下文满）**

```
sessionStart → 加载记忆
对话...（上下文逐渐填满）
preCompact 触发 → Agent 提取细粒度事实写入 daily.jsonl     ← 第一道保存
对话继续...
stop 触发 → Agent 生成摘要写入 sessions.jsonl              ← 第二道保存
```

两道保存都触发，信息完整保留。

**场景 2：短会话（上下文未满）**

```
sessionStart → 加载记忆
对话...（上下文未达 80%）
stop 触发 → Agent 生成摘要 + 提取关键事实                   ← 兜底保存
```

preCompact 未触发，但 stop Hook 的 `[Session Save]` 指令已增强为同时要求 Agent 提取关键事实（如果 preCompact 未触发）。因此信息不会丢失。

**场景 3：异常中断（crash / 手动关闭）**

```
sessionStart → 加载记忆
对话...
[异常中断]                                                   ← 两个 Hook 都未触发
```

这是唯一可能丢失信息的场景。如果 Cursor 异常崩溃或用户直接关闭窗口，stop Hook 不会被触发。但这种情况下：
- 异常中断通常是少见的
- 下次会话可以通过对话自然恢复（Agent 还记得上下文压缩后的摘要内容）
- 如果频繁异常中断，可以通过 Rules 增加"Agent 每完成一个子任务就主动保存"的行为

### 是否需要每次执行后都 Hook 存储？

**不需要**，原因如下：

| 方案 | 写入频率 | 优点 | 缺点 |
|------|----------|------|------|
| 每次 Agent 响应后都写入 | 极高 | 零信息丢失 | 大量无价值写入（"好的"、"收到"也写入）；显著拖慢响应 |
| 仅 preCompact + stop 写入 | 低（每次会话 1-2 次） | 只保存有价值的信息；性能零影响 | 异常中断时可能丢失 |
| **当前方案（推荐）** | 适中 | 平衡信息完整性和性能 | — |

每次 Agent 响应后都 Hook 存储的问题：
1. **大量噪声**：Agent 的每个响应都不一定包含值得记忆的信息
2. **性能影响**：频繁 Shell 写入会拖慢 Agent 响应
3. **Cursor 不支持**：目前 Hooks 系统没有"每次 Agent 响应后"的事件，只有 sessionStart / preCompact / stop

当前方案的保存策略已经足够覆盖绝大多数场景：preCompact 在长会话中保存细粒度事实，stop 在任务完成时兜底保存摘要和事实。

---

## Q2: sessionStart 搜索 SQLite 时用户还没输入，怎么搜？

**简短回答**：sessionStart 不做"搜索"，只做"加载近期记忆"。真正的搜索在对话过程中由 Agent 主动完成。

### 详细解释

sessionStart Hook 的加载策略是**基于时间**，而不是基于用户输入：

| 数据 | 加载方式 | 是否需要关键词 |
|------|----------|---------------|
| MEMORY.md | 全量加载 | 否 |
| facts.jsonl | 最近 7 天、最多 15 条 | 否（按时间排序） |
| sessions.jsonl | 最近 1 条摘要 | 否（取最新） |

这些是"最近记忆"的被动加载，不需要知道用户要问什么。

当用户在对话中提到"之前讨论过"或需要历史信息时，**Agent 会主动调用 `search_memory.py`**，此时才使用用户的问题作为搜索关键词：

```bash
python3 ~/.cursor/skills/memory/scripts/search_memory.py "Redis 缓存方案"
```

这个搜索通过 SQLite FTS5（关键词匹配）+ 向量相似度（语义匹配）进行，能找到相关的历史记忆。

### 流程时序

```
1. sessionStart → 加载近期记忆（按时间，无需关键词）
2. Agent 上下文中已有近期记忆
3. 用户输入问题
4. Agent 判断是否需要更多历史信息
   → 是 → Agent 调用 search_memory.py（使用用户问题作为关键词）
   → 否 → 直接用已有上下文回答
5. Agent 回答用户
```

---

## Q3: 嵌入模型的"语义搜索"具体是怎么工作的？

### 什么是嵌入向量

嵌入模型将一段文本转换为一个数值向量（如 512 维的浮点数数组）。语义相近的文本，其向量在空间中距离更近。

```
"数据库优化" → [0.12, -0.34, 0.56, ...]     ← 512个数字
"PostgreSQL 性能调优" → [0.11, -0.33, 0.55, ...]   ← 与上面很接近
"天气预报" → [-0.78, 0.45, -0.12, ...]       ← 与上面距离很远
```

### 搜索过程

1. 用户搜索 "数据库优化"
2. `search_memory.py` 将查询文本转为向量
3. SQLite 中存储了所有记忆的向量
4. 计算查询向量与每条记忆向量的余弦相似度
5. 返回相似度最高的结果

```
查询: "数据库优化" → 向量 Q

记忆1: "Redis 缓存设置" → 向量 V1 → cos(Q, V1) = 0.45
记忆2: "PostgreSQL 索引设计" → 向量 V2 → cos(Q, V2) = 0.89  ← 最相关
记忆3: "API 路由设计" → 向量 V3 → cos(Q, V3) = 0.23

结果: 记忆2（PostgreSQL 索引设计）得分最高
```

### 为什么需要本地模型

使用本地嵌入模型（如 BGE-small-zh-v1.5）而非 API：
- 零外部依赖，离线可用
- 无 API 费用
- 数据不出本机，隐私安全
- 响应更快（本地推理 vs 网络请求）

> 详细的模型选型见 [11-本地嵌入模型选型](./2026-02-18-11-本地嵌入模型选型.md)

---

## 相关文档

- [03-记忆生命周期](./2026-02-18-03-记忆生命周期.md) — 完整会话流程和无压缩保障
- [04-Hook 详细设计](./2026-02-18-04-Hook详细设计.md) — 各 Hook 的实现逻辑
- [08-SQLite 索引设计](./2026-02-18-08-SQLite索引设计.md) — 搜索技术细节
- [11-本地嵌入模型选型](./2026-02-18-11-本地嵌入模型选型.md) — 嵌入模型选择
