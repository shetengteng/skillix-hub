#!/usr/bin/env python3
"""
Swagger API è¯»å–å™¨ - è·å–ã€è§£æå¹¶ç¼“å­˜ Swagger/OpenAPI æ–‡æ¡£
"""

import argparse
import hashlib
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional
from urllib.parse import urlparse

import requests
import yaml

from doc_generator import generate_api_doc


def fetch_with_browser(url: str, timeout: int = 120) -> tuple:
    """ä½¿ç”¨æµè§ˆå™¨è·å–å†…å®¹ï¼ˆç”¨äºéœ€è¦ç™»å½•è®¤è¯çš„åœºæ™¯ï¼‰"""
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.common.by import By
    except ImportError:
        raise Exception("æµè§ˆå™¨æ¨¡å¼éœ€è¦ seleniumï¼Œè¯·è¿è¡Œ: pip install selenium")
    
    import time
    from urllib.parse import urljoin, urlparse
    
    print(f"\nğŸŒ æ­£åœ¨æ‰“å¼€æµè§ˆå™¨...")
    print(f"   URL: {url}")
    print(f"   è¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•ï¼Œé¡µé¢åŠ è½½å®Œæˆåå°†è‡ªåŠ¨å…³é—­\n")
    
    options = Options()
    options.add_argument("--start-maximized")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    
    driver = None
    try:
        driver = webdriver.Chrome(options=options)
        driver.get(url)
        
        print("â³ ç­‰å¾… Swagger UI åŠ è½½...\n")
        
        start_time = datetime.now()
        content = None
        actual_url = url
        
        while (datetime.now() - start_time).seconds < timeout:
            time.sleep(3)
            
            current_url = driver.current_url
            page_source = driver.page_source
            elapsed = (datetime.now() - start_time).seconds
            
            # æ£€æµ‹ Swagger UI æ˜¯å¦å·²åŠ è½½
            swagger_loaded = False
            try:
                swagger_ui = driver.find_elements(By.CLASS_NAME, "swagger-ui")
                info_section = driver.find_elements(By.CLASS_NAME, "info")
                operations = driver.find_elements(By.CLASS_NAME, "opblock")
                
                if swagger_ui and (info_section or operations):
                    swagger_loaded = True
                    print(f"âœ… æ£€æµ‹åˆ° Swagger UIï¼ˆ{len(operations)} ä¸ªæ¥å£ï¼‰")
            except Exception:
                print(f"   æ£€æŸ¥é¡µé¢ä¸­... ({elapsed}s)")
            
            if swagger_loaded:
                # å°è¯•ä»é¡µé¢æå– API æ–‡æ¡£ URL
                extracted_url = extract_swagger_url_from_html(page_source, current_url)
                
                if not extracted_url:
                    # å°è¯•å¸¸è§è·¯å¾„
                    parsed = urlparse(current_url)
                    base = f"{parsed.scheme}://{parsed.netloc}"
                    path_prefix = ""
                    if "/swagger-ui" in parsed.path:
                        path_prefix = parsed.path.split("/swagger-ui")[0]
                    
                    common_paths = [
                        f"{path_prefix}/v3/api-docs",
                        f"{path_prefix}/v2/api-docs",
                        f"{path_prefix}/api-docs",
                        f"{path_prefix}/swagger.json",
                        "/v3/api-docs",
                        "/v2/api-docs",
                        "/api-docs",
                    ]
                    
                    for path in common_paths:
                        test_url = urljoin(base, path)
                        print(f"   å°è¯•: {test_url}")
                        try:
                            driver.get(test_url)
                            time.sleep(2)
                            
                            body_text = driver.find_element(By.TAG_NAME, "body").text
                            if body_text.strip().startswith("{"):
                                try:
                                    data = json.loads(body_text)
                                    if "swagger" in data or "openapi" in data or "paths" in data:
                                        print(f"âœ… æ‰¾åˆ° API æ–‡æ¡£: {test_url}")
                                        content = body_text
                                        actual_url = test_url
                                        break
                                except json.JSONDecodeError:
                                    pass
                            
                            # æ£€æŸ¥ pre æ ‡ç­¾
                            pre_elements = driver.find_elements(By.TAG_NAME, "pre")
                            if pre_elements:
                                pre_text = pre_elements[0].text
                                if pre_text.strip().startswith("{"):
                                    try:
                                        data = json.loads(pre_text)
                                        if "swagger" in data or "openapi" in data or "paths" in data:
                                            print(f"âœ… æ‰¾åˆ° API æ–‡æ¡£: {test_url}")
                                            content = pre_text
                                            actual_url = test_url
                                            break
                                    except json.JSONDecodeError:
                                        pass
                        except Exception:
                            continue
                    
                    if content:
                        break
                else:
                    print(f"âœ… æ‰¾åˆ° API æ–‡æ¡£ URL: {extracted_url}")
                    driver.get(extracted_url)
                    time.sleep(2)
                    
                    try:
                        pre_elements = driver.find_elements(By.TAG_NAME, "pre")
                        if pre_elements:
                            content = pre_elements[0].text
                        else:
                            content = driver.find_element(By.TAG_NAME, "body").text
                        actual_url = extracted_url
                        break
                    except Exception as e:
                        print(f"   è·å–å†…å®¹å¤±è´¥: {e}")
            
            if elapsed % 15 == 0 and elapsed > 0:
                print(f"   ç­‰å¾…ä¸­... ({elapsed}s)")
        
        if not content:
            raise Exception(f"è¶…æ—¶ ({timeout}s)ï¼Œæœªèƒ½è·å– API æ–‡æ¡£")
        
        return content, actual_url
        
    finally:
        if driver:
            print("\nğŸ”’ å…³é—­æµè§ˆå™¨...")
            driver.quit()


# ç¼“å­˜ç›®å½•
SCRIPT_DIR = Path(__file__).parent.parent
CACHE_DIR = SCRIPT_DIR / "cache"
INDEX_FILE = CACHE_DIR / "index.json"


def get_api_hash(url: str) -> str:
    """ç”Ÿæˆ URL çš„å“ˆå¸Œå€¼"""
    return hashlib.md5(url.encode()).hexdigest()[:12]


def load_index() -> dict:
    """åŠ è½½ç´¢å¼•æ–‡ä»¶"""
    if INDEX_FILE.exists():
        with open(INDEX_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"apis": []}


def save_index(index: dict) -> None:
    """ä¿å­˜ç´¢å¼•æ–‡ä»¶"""
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    with open(INDEX_FILE, "w", encoding="utf-8") as f:
        json.dump(index, f, indent=2, ensure_ascii=False)


def find_api_by_alias_or_url(alias: Optional[str] = None, url: Optional[str] = None) -> Optional[dict]:
    """é€šè¿‡åˆ«åæˆ– URL æŸ¥æ‰¾ API"""
    index = load_index()
    for api in index["apis"]:
        if alias and api.get("alias") == alias:
            return api
        if url and api.get("url") == url:
            return api
    return None


def build_auth_headers(auth_type: Optional[str], **kwargs) -> dict:
    """æ„å»ºè®¤è¯è¯·æ±‚å¤´"""
    headers = {}
    
    if not auth_type:
        return headers
    
    if auth_type == "bearer":
        token = kwargs.get("token")
        if token:
            headers["Authorization"] = f"Bearer {token}"
    
    elif auth_type == "basic":
        import base64
        username = kwargs.get("username", "")
        password = kwargs.get("password", "")
        credentials = base64.b64encode(f"{username}:{password}".encode()).decode()
        headers["Authorization"] = f"Basic {credentials}"
    
    elif auth_type == "apikey":
        key_name = kwargs.get("key_name")
        key_value = kwargs.get("key_value")
        key_in = kwargs.get("key_in", "header")
        if key_in == "header" and key_name and key_value:
            headers[key_name] = key_value
    
    return headers


def build_auth_params(auth_type: Optional[str], **kwargs) -> dict:
    """æ„å»ºè®¤è¯æŸ¥è¯¢å‚æ•°"""
    params = {}
    
    if auth_type == "apikey":
        key_name = kwargs.get("key_name")
        key_value = kwargs.get("key_value")
        key_in = kwargs.get("key_in", "header")
        if key_in == "query" and key_name and key_value:
            params[key_name] = key_value
    
    return params


def extract_swagger_url_from_html(html_content: str, base_url: str) -> Optional[str]:
    """ä» Swagger UI HTML é¡µé¢æå– API æ–‡æ¡£ URL"""
    import re
    from urllib.parse import urljoin
    
    patterns = [
        r'url\s*:\s*["\']([^"\']+)["\']',
        r'configUrl\s*:\s*["\']([^"\']+)["\']',
        r'spec-url\s*=\s*["\']([^"\']+)["\']',
        r'data-url\s*=\s*["\']([^"\']+)["\']',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, html_content)
        if match:
            found_url = match.group(1)
            if not found_url.startswith(('http://', 'https://')):
                found_url = urljoin(base_url, found_url)
            return found_url
    
    return None


def guess_swagger_json_url(html_url: str) -> list:
    """çŒœæµ‹å¯èƒ½çš„ Swagger JSON URL"""
    from urllib.parse import urlparse, urljoin
    
    parsed = urlparse(html_url)
    base = f"{parsed.scheme}://{parsed.netloc}"
    
    common_paths = [
        "/v3/api-docs", "/v2/api-docs", "/api-docs",
        "/swagger.json", "/openapi.json",
        "/api/swagger.json", "/api/openapi.json",
        "/swagger/v1/swagger.json", "/swagger/v2/swagger.json",
    ]
    
    if "swagger-ui" in html_url:
        path_base = parsed.path.rsplit("/swagger-ui", 1)[0]
        for p in common_paths:
            common_paths.append(path_base + p)
    
    return [urljoin(base, p) for p in common_paths]


def fetch_swagger(url: str, auth_type: Optional[str] = None, verify_ssl: bool = True, 
                  use_browser: bool = False, browser_timeout: int = 120, **auth_kwargs) -> tuple[dict, str]:
    """è·å– Swagger/OpenAPI æ–‡æ¡£ï¼Œè¿”å› (æ•°æ®, å®é™…URL)"""
    
    # æµè§ˆå™¨æ¨¡å¼
    if use_browser:
        content, actual_url = fetch_with_browser(url, browser_timeout)
        try:
            return json.loads(content), actual_url
        except json.JSONDecodeError:
            try:
                return yaml.safe_load(content), actual_url
            except yaml.YAMLError:
                raise Exception("æ— æ³•è§£ææµè§ˆå™¨è·å–çš„å†…å®¹")
    
    headers = build_auth_headers(auth_type, **auth_kwargs)
    params = build_auth_params(auth_type, **auth_kwargs)
    headers["Accept"] = "application/json, application/yaml, text/html, */*"
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30, verify=verify_ssl)
        response.raise_for_status()
    except requests.exceptions.HTTPError as e:
        if e.response.status_code in (401, 403):
            raise Exception(f"è®¤è¯å¤±è´¥ (HTTP {e.response.status_code})ï¼Œè¯·æä¾›æœ‰æ•ˆçš„è®¤è¯ä¿¡æ¯")
        raise Exception(f"HTTP é”™è¯¯: {e}")
    except requests.exceptions.RequestException as e:
        raise Exception(f"è¯·æ±‚å¤±è´¥: {e}")
    
    content_type = response.headers.get("Content-Type", "")
    content = response.text
    
    # æ£€æµ‹æ˜¯å¦ä¸º HTML é¡µé¢
    if "text/html" in content_type or content.strip().startswith(("<!DOCTYPE", "<html", "<HTML")):
        print("æ£€æµ‹åˆ° Swagger UI HTML é¡µé¢ï¼Œæ­£åœ¨æå– API æ–‡æ¡£ URL...")
        
        extracted_url = extract_swagger_url_from_html(content, url)
        if extracted_url:
            print(f"æ‰¾åˆ° API æ–‡æ¡£ URL: {extracted_url}")
            return fetch_swagger(extracted_url, auth_type, verify_ssl, **auth_kwargs)
        
        print("å°è¯•å¸¸è§ Swagger JSON è·¯å¾„...")
        guessed_urls = guess_swagger_json_url(url)
        
        for guessed_url in guessed_urls:
            try:
                headers_json = headers.copy()
                headers_json["Accept"] = "application/json, application/yaml"
                resp = requests.get(guessed_url, headers=headers_json, params=params, 
                                   timeout=10, verify=verify_ssl)
                if resp.status_code == 200:
                    try:
                        data = json.loads(resp.text)
                        if "swagger" in data or "openapi" in data or "paths" in data:
                            print(f"æ‰¾åˆ° API æ–‡æ¡£: {guessed_url}")
                            return data, guessed_url
                    except json.JSONDecodeError:
                        try:
                            data = yaml.safe_load(resp.text)
                            if isinstance(data, dict) and ("swagger" in data or "openapi" in data or "paths" in data):
                                print(f"æ‰¾åˆ° API æ–‡æ¡£: {guessed_url}")
                                return data, guessed_url
                        except yaml.YAMLError:
                            pass
            except requests.exceptions.RequestException:
                continue
        
        raise Exception("æ— æ³•æ‰¾åˆ° Swagger JSON URLï¼Œè¯·ç›´æ¥æä¾› JSON/YAML URL")
    
    # å°è¯•è§£æ JSON
    try:
        return json.loads(content), url
    except json.JSONDecodeError:
        pass
    
    # å°è¯•è§£æ YAML
    try:
        return yaml.safe_load(content), url
    except yaml.YAMLError:
        pass
    
    raise Exception("æ— æ³•è§£æå“åº”å†…å®¹ä¸º JSON æˆ– YAML")


def cmd_add(args) -> None:
    """æ·»åŠ æ–° API"""
    url = args.url
    alias = args.alias or urlparse(url).netloc.replace(".", "-")
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    existing = find_api_by_alias_or_url(alias=alias)
    if existing:
        print(f"é”™è¯¯: åˆ«å '{alias}' å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨ 'refresh' æ›´æ–°")
        sys.exit(1)
    
    existing_url = find_api_by_alias_or_url(url=url)
    if existing_url:
        print(f"é”™è¯¯: URL å·²ç¼“å­˜ï¼Œåˆ«åä¸º '{existing_url['alias']}'ï¼Œè¯·ä½¿ç”¨ 'refresh' æ›´æ–°")
        sys.exit(1)
    
    print(f"æ­£åœ¨è·å– Swagger: {url}")
    
    auth_kwargs = {
        "token": args.token,
        "username": args.username,
        "password": args.password,
        "key_name": args.key_name,
        "key_value": args.key_value,
        "key_in": args.key_in,
    }
    
    try:
        swagger_data, actual_url = fetch_swagger(
            url, args.auth_type, 
            verify_ssl=not args.no_verify,
            use_browser=args.browser,
            browser_timeout=args.browser_timeout,
            **auth_kwargs
        )
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)
    
    if actual_url != url:
        print(f"ä½¿ç”¨å®é™… API æ–‡æ¡£ URL: {actual_url}")
        url = actual_url
    
    # æå–ä¿¡æ¯
    info = swagger_data.get("info", {})
    title = info.get("title", "Unknown API")
    version = info.get("version", "unknown")
    description = info.get("description", "")
    
    # ç»Ÿè®¡æ¥å£æ•°é‡
    paths = swagger_data.get("paths", {})
    endpoint_count = sum(len([m for m in p.keys() if m in ("get", "post", "put", "delete", "patch")])
                        for p in paths.values())
    
    # åˆ›å»ºç¼“å­˜ç›®å½•
    api_hash = get_api_hash(url)
    api_dir = CACHE_DIR / api_hash
    api_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜åŸå§‹æ•°æ®
    with open(api_dir / "raw.json", "w", encoding="utf-8") as f:
        json.dump(swagger_data, f, indent=2, ensure_ascii=False)
    
    # ç”Ÿæˆå¹¶ä¿å­˜æ–‡æ¡£
    doc_content = generate_api_doc(swagger_data, url)
    with open(api_dir / "api-doc.md", "w", encoding="utf-8") as f:
        f.write(doc_content)
    
    # ä¿å­˜å…ƒæ•°æ®
    now = datetime.now().isoformat()
    meta = {
        "url": url,
        "alias": alias,
        "title": title,
        "version": version,
        "description": description[:200] if description else "",
        "endpoint_count": endpoint_count,
        "created_at": now,
        "updated_at": now,
        "auth_type": args.auth_type,
    }
    
    with open(api_dir / "meta.json", "w", encoding="utf-8") as f:
        json.dump(meta, f, indent=2, ensure_ascii=False)
    
    # æ›´æ–°ç´¢å¼•
    index = load_index()
    index["apis"].append({
        "id": api_hash,
        "alias": alias,
        "url": url,
        "title": title,
        "version": version,
        "last_updated": now,
    })
    save_index(index)
    
    print(f"\nâœ… API æ·»åŠ æˆåŠŸ!")
    print(f"   åˆ«å: {alias}")
    print(f"   æ ‡é¢˜: {title}")
    print(f"   ç‰ˆæœ¬: {version}")
    print(f"   æ¥å£æ•°: {endpoint_count}")
    print(f"\nä½¿ç”¨ 'swagger read --alias {alias}' æŸ¥çœ‹æ–‡æ¡£")


def cmd_list(args) -> None:
    """åˆ—å‡ºæ‰€æœ‰å·²ç¼“å­˜çš„ API"""
    index = load_index()
    
    if not index["apis"]:
        print("æš‚æ— ç¼“å­˜çš„ APIï¼Œè¯·ä½¿ç”¨ 'add' å‘½ä»¤æ·»åŠ ")
        return
    
    print("\nğŸ“š å·²ç¼“å­˜çš„ API:\n")
    print(f"{'åˆ«å':<20} {'æ ‡é¢˜':<30} {'ç‰ˆæœ¬':<10} {'æ›´æ–°æ—¶é—´':<20}")
    print("-" * 80)
    
    for api in index["apis"]:
        alias = api.get("alias", "N/A")[:19]
        title = api.get("title", "N/A")[:29]
        version = api.get("version", "N/A")[:9]
        updated = api.get("last_updated", "N/A")[:19]
        print(f"{alias:<20} {title:<30} {version:<10} {updated:<20}")
    
    print(f"\nå…± {len(index['apis'])} ä¸ª API")


def cmd_read(args) -> None:
    """è¯»å–å¹¶è¾“å‡º API æ–‡æ¡£"""
    api = find_api_by_alias_or_url(alias=args.alias, url=args.url)
    
    if not api:
        identifier = args.alias or args.url
        print(f"é”™è¯¯: æœªæ‰¾åˆ° API '{identifier}'ï¼Œè¯·ä½¿ç”¨ 'list' æŸ¥çœ‹å¯ç”¨çš„ API")
        sys.exit(1)
    
    api_dir = CACHE_DIR / api["id"]
    doc_file = api_dir / "api-doc.md"
    
    if not doc_file.exists():
        print(f"é”™è¯¯: æ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å°è¯• 'refresh --alias {api['alias']}'")
        sys.exit(1)
    
    with open(doc_file, "r", encoding="utf-8") as f:
        print(f.read())


def cmd_refresh(args) -> None:
    """åˆ·æ–° API ç¼“å­˜"""
    api = find_api_by_alias_or_url(alias=args.alias, url=args.url)
    
    if not api:
        identifier = args.alias or args.url
        print(f"é”™è¯¯: æœªæ‰¾åˆ° API '{identifier}'ï¼Œè¯·å…ˆä½¿ç”¨ 'add' æ·»åŠ ")
        sys.exit(1)
    
    api_dir = CACHE_DIR / api["id"]
    meta_file = api_dir / "meta.json"
    
    with open(meta_file, "r", encoding="utf-8") as f:
        meta = json.load(f)
    
    url = meta["url"]
    print(f"æ­£åœ¨åˆ·æ–° API: {url}")
    
    auth_type = args.auth_type or meta.get("auth_type")
    auth_kwargs = {
        "token": args.token,
        "username": args.username,
        "password": args.password,
        "key_name": args.key_name,
        "key_value": args.key_value,
        "key_in": args.key_in,
    }
    
    try:
        swagger_data, _ = fetch_swagger(
            url, auth_type, 
            verify_ssl=not args.no_verify,
            use_browser=args.browser,
            browser_timeout=args.browser_timeout,
            **auth_kwargs
        )
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)
    
    # æ›´æ–°ä¿¡æ¯
    info = swagger_data.get("info", {})
    paths = swagger_data.get("paths", {})
    endpoint_count = sum(len([m for m in p.keys() if m in ("get", "post", "put", "delete", "patch")])
                        for p in paths.values())
    
    with open(api_dir / "raw.json", "w", encoding="utf-8") as f:
        json.dump(swagger_data, f, indent=2, ensure_ascii=False)
    
    doc_content = generate_api_doc(swagger_data, url)
    with open(api_dir / "api-doc.md", "w", encoding="utf-8") as f:
        f.write(doc_content)
    
    now = datetime.now().isoformat()
    meta.update({
        "title": info.get("title", meta.get("title")),
        "version": info.get("version", meta.get("version")),
        "description": info.get("description", "")[:200],
        "endpoint_count": endpoint_count,
        "updated_at": now,
        "auth_type": auth_type,
    })
    
    with open(meta_file, "w", encoding="utf-8") as f:
        json.dump(meta, f, indent=2, ensure_ascii=False)
    
    index = load_index()
    for idx_api in index["apis"]:
        if idx_api["id"] == api["id"]:
            idx_api["title"] = meta["title"]
            idx_api["version"] = meta["version"]
            idx_api["last_updated"] = now
            break
    save_index(index)
    
    print(f"\nâœ… API åˆ·æ–°æˆåŠŸ!")
    print(f"   æ ‡é¢˜: {meta['title']}")
    print(f"   ç‰ˆæœ¬: {meta['version']}")
    print(f"   æ¥å£æ•°: {endpoint_count}")


def cmd_remove(args) -> None:
    """åˆ é™¤ API ç¼“å­˜"""
    api = find_api_by_alias_or_url(alias=args.alias, url=args.url)
    
    if not api:
        identifier = args.alias or args.url
        print(f"é”™è¯¯: æœªæ‰¾åˆ° API '{identifier}'")
        sys.exit(1)
    
    import shutil
    
    api_dir = CACHE_DIR / api["id"]
    if api_dir.exists():
        shutil.rmtree(api_dir)
    
    index = load_index()
    index["apis"] = [a for a in index["apis"] if a["id"] != api["id"]]
    save_index(index)
    
    print(f"âœ… API '{api['alias']}' å·²åˆ é™¤")


def main():
    parser = argparse.ArgumentParser(description="Swagger API è¯»å–å™¨")
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # add å‘½ä»¤
    add_parser = subparsers.add_parser("add", help="æ·»åŠ æ–° API")
    add_parser.add_argument("--url", required=True, help="Swagger/OpenAPI URL")
    add_parser.add_argument("--alias", help="API åˆ«åï¼ˆå¯é€‰ï¼‰")
    add_parser.add_argument("--auth-type", choices=["bearer", "basic", "apikey"], help="è®¤è¯ç±»å‹")
    add_parser.add_argument("--token", help="Bearer token")
    add_parser.add_argument("--username", help="Basic auth ç”¨æˆ·å")
    add_parser.add_argument("--password", help="Basic auth å¯†ç ")
    add_parser.add_argument("--key-name", help="API key åç§°")
    add_parser.add_argument("--key-value", help="API key å€¼")
    add_parser.add_argument("--key-in", choices=["header", "query"], default="header", help="API key ä½ç½®")
    add_parser.add_argument("--no-verify", action="store_true", help="è·³è¿‡ SSL éªŒè¯")
    add_parser.add_argument("--browser", action="store_true", help="ä½¿ç”¨æµè§ˆå™¨æ¨¡å¼ï¼ˆSSO/OAuthï¼‰")
    add_parser.add_argument("--browser-timeout", type=int, default=120, help="æµè§ˆå™¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰")
    
    # list å‘½ä»¤
    subparsers.add_parser("list", help="åˆ—å‡ºå·²ç¼“å­˜çš„ API")
    
    # read å‘½ä»¤
    read_parser = subparsers.add_parser("read", help="è¯»å– API æ–‡æ¡£")
    read_parser.add_argument("--alias", help="API åˆ«å")
    read_parser.add_argument("--url", help="API URL")
    
    # refresh å‘½ä»¤
    refresh_parser = subparsers.add_parser("refresh", help="åˆ·æ–° API æ–‡æ¡£")
    refresh_parser.add_argument("--alias", help="API åˆ«å")
    refresh_parser.add_argument("--url", help="API URL")
    refresh_parser.add_argument("--auth-type", choices=["bearer", "basic", "apikey"], help="è®¤è¯ç±»å‹")
    refresh_parser.add_argument("--token", help="Bearer token")
    refresh_parser.add_argument("--username", help="Basic auth ç”¨æˆ·å")
    refresh_parser.add_argument("--password", help="Basic auth å¯†ç ")
    refresh_parser.add_argument("--key-name", help="API key åç§°")
    refresh_parser.add_argument("--key-value", help="API key å€¼")
    refresh_parser.add_argument("--key-in", choices=["header", "query"], default="header", help="API key ä½ç½®")
    refresh_parser.add_argument("--no-verify", action="store_true", help="è·³è¿‡ SSL éªŒè¯")
    refresh_parser.add_argument("--browser", action="store_true", help="ä½¿ç”¨æµè§ˆå™¨æ¨¡å¼")
    refresh_parser.add_argument("--browser-timeout", type=int, default=120, help="æµè§ˆå™¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰")
    
    # remove å‘½ä»¤
    remove_parser = subparsers.add_parser("remove", help="åˆ é™¤ API ç¼“å­˜")
    remove_parser.add_argument("--alias", help="API åˆ«å")
    remove_parser.add_argument("--url", help="API URL")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    commands = {
        "add": cmd_add,
        "list": cmd_list,
        "read": cmd_read,
        "refresh": cmd_refresh,
        "remove": cmd_remove,
    }
    
    commands[args.command](args)


if __name__ == "__main__":
    main()
